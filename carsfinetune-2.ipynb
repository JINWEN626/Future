{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e179f97-8e22-46a4-aa97-abecbfe01b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e619d996-aafc-4c09-9022-fad98275e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import scipy.io\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm.notebook import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3b3ae6-7db5-46b8-9360-617536be08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d96438-fe39-4b64-94d6-7aa6a9496435",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72153926-12c6-4298-8bb6-3ff98e79cfb3",
   "metadata": {},
   "source": [
    "对一张网络上的图片进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161e60c8-6300-4bfb-b0e2-4a44f918c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "#Here we need to give CLIP a texual descriptions of image\n",
    "#CLIP will find the one which matches with the image the most out of the list\n",
    "inputs = processor(\n",
    "    text=[\"a photo of a cat\", \"a photo of a dog\"], images=[image], return_tensors=\"pt\", padding=True\n",
    ")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057b4933-2802-4d4c-9eee-6fcb8e23725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9949, 0.0051]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caad847-e5a4-4aa6-b6e1-6a7b18c749e9",
   "metadata": {},
   "source": [
    "构建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c2d493-004b-4c8b-addf-31951d2b9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanfordCars(Dataset):\n",
    "  def __init__(self,metaPath,imgDir,labelMeta,model_name=\"openai/clip-vit-base-patch32\",cuda=False):\n",
    "    \"\"\"\n",
    "    mataPath: path to the annotation file\n",
    "\n",
    "    imgDir: Where images are stored\n",
    "\n",
    "    labelMeta: File where label data is stored\n",
    "\n",
    "    model_name: Name of model we need to store. It is needed because we need to use the\n",
    "    processor of the particular model to process inputs.\n",
    "\n",
    "    cuda : To enable gpu acceleration    \n",
    "\n",
    "    text: to store text like \"This is image of {image} car\"\n",
    "\n",
    "    textInput: Input_ids of the text which needs to be passed to CLIP model\n",
    "\n",
    "    \"\"\"\n",
    "    super(StanfordCars,self).__init__()\n",
    "    self.metaPath = metaPath\n",
    "    self.labelMeta = labelMeta\n",
    "    self.path = imgDir\n",
    "    train_data = scipy.io.loadmat(self.metaPath)\n",
    "    class_data = scipy.io.loadmat(self.labelMeta)\n",
    "    #class names\n",
    "    self.classes = class_data['class_names'][0]\n",
    "    # This is our data i.e filenames and their labels\n",
    "    self.data = train_data['annotations'][0]\n",
    "    # To process inputs\n",
    "    self.processor = CLIPProcessor.from_pretrained(model_name)\n",
    "    self.text = []\n",
    "    self.textInput = None\n",
    "    self.cuda = cuda\n",
    "\n",
    "  def processLabels(self):\n",
    "    \"\"\"\n",
    "    Only needs to process text once since every image will belong to at least one class in labels.\n",
    "    We just process labels one time and then add these 'input_ids' to our images. We will append these later\n",
    "    to our image pixel_values and pass the whole dict to CLIP model.\n",
    "    \"\"\"\n",
    "    for i in self.classes:\n",
    "      # Adding text prompt to help clip\n",
    "      self.text.append(f'This is photo of {i[0]} car')\n",
    "    #processing this text\n",
    "    self.textInput = self.processor(text=self.text,return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    if(self.cuda):\n",
    "      for k in self.textInput.keys():\n",
    "        self.textInput[k] = self.textInput[k].cuda()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    #just to check of processLable method is run or not.\n",
    "    assert self.textInput!=None,'run the processLabels method'\n",
    "\n",
    "    bbox_x1,bbox_x2,bbox_y1,bbox_y2,label,fname = self.data[idx]\n",
    "\n",
    "    label = label.item() - 1 # because labeling starts from 1 in metadata file\n",
    "    pth = self.path+'/'+fname.item()\n",
    "    img = Image.open(pth)\n",
    "    img = img.convert('RGB')\n",
    "    #using CLIP processor to apply image pre-processing\n",
    "    img = self.processor(images=img,return_tensors=\"pt\")\n",
    "    img['pixel_values'] = img['pixel_values'].squeeze() # by default batch size is one\n",
    "\n",
    "    if(self.cuda):\n",
    "      img['pixel_values'] = img['pixel_values'].cuda()\n",
    "\n",
    "    return (img,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c026ecc-d25f-45d5-a5e9-71d8897fc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StanfordCars(metaPath='content/devkit/cars_train_annos.mat',imgDir='content/cars_train',labelMeta='content/devkit/cars_meta.mat',cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53662f18-7472-496e-ace9-624a176a8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.processLabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "162b29e3-ac24-445c-92bf-cb541536968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_split(dataset,per,seed):\n",
    "  \"\"\"\n",
    "  dataset: Full dataset object\n",
    "\n",
    "  per: How much train test split\n",
    "\n",
    "  seed: Random seed\n",
    "\n",
    "  Splitting dataset.data which contains file name and labels into two parts.\n",
    "  and then creating two different dataset for train and eval\n",
    "  \"\"\"\n",
    "  train_data,test_data = train_test_split(dataset.data,test_size = per,random_state=seed)\n",
    "  dataset.data = train_data\n",
    "  evalDataset = StanfordCars(metaPath='content/devkit/cars_train_annos.mat',imgDir='content/cars_train',labelMeta='content/devkit/cars_meta.mat',cuda=True)\n",
    "  evalDataset.processLabels()\n",
    "  evalDataset.data = test_data\n",
    "  return (dataset,evalDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23e3c316-8918-49d0-b837-76bf30b7b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData,evalData = train_eval_split(dataset,0.05,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79424587-5c7e-43d5-8ca6-8249f7b22517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7736"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae37728-ba57-419f-a0e0-e7784c61c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(trainData,batch_size=64,shuffle=True)\n",
    "evalLoader = DataLoader(evalData,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32badd2-c76a-469e-b23d-854d56e3aaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c197d201374ddd9103a626870b529e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "truth = []\n",
    "#we defined eariler\n",
    "model.cuda()\n",
    "model.eval()\n",
    "for inputs,label in tq(evalLoader):\n",
    "  #add the attention mask and input_ids to input image pixel values\n",
    "  for k in evalData.textInput.keys():\n",
    "    inputs[k] = evalData.textInput[k]\n",
    "  outputs = model(**inputs)\n",
    "  logits_per_image = outputs.logits_per_image\n",
    "  probs = logits_per_image.softmax(dim=1)\n",
    "  preds =  torch.argmax(probs, dim=1)\n",
    "  preds=preds.cpu()\n",
    "  for i in preds:\n",
    "    predictions.append(i.item())\n",
    "  for j in label:\n",
    "    truth.append(j.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed33770-de27-43c4-9f8b-24fcb3fe8a43",
   "metadata": {},
   "source": [
    "zero shot 时 clip 对 stanfordcars 数据集的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee80edcb-52b0-424b-b3d0-71c4278d689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5857843137254902\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(truth,predictions)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbaf1d78-74b5-44f5-9046-f52933f693ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5627612410558148\n"
     ]
    }
   ],
   "source": [
    "score = f1_score(truth,predictions,average='weighted')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e1c2a-5067-448f-815d-eb0f6fd572e9",
   "metadata": {},
   "source": [
    "linear probe 后， clip 对 stanfordcars数据集的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "685ec327-cd3c-462a-a981-963e287c9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneCLIP(nn.Module):\n",
    "  def __init__(self,out_shape=196,model_name=\"openai/clip-vit-base-patch32\",freeze=True):\n",
    "    super(FineTuneCLIP,self).__init__()\n",
    "    self.CLIP = CLIPModel.from_pretrained(model_name)\n",
    "    # Freezing the CLIP model\n",
    "    if(freeze):\n",
    "      for parameter in self.CLIP.parameters():\n",
    "        parameter.requires_grad=False\n",
    "    # Adding extra last layers\n",
    "    self.fc1 = nn.Sequential(\n",
    "        nn.Linear(out_shape,out_shape*5),\n",
    "        nn.BatchNorm1d(out_shape*5),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.25)\n",
    "    )\n",
    "\n",
    "    self.fc2 =  nn.Sequential(\n",
    "        nn.Linear(out_shape*5,out_shape*5),\n",
    "        nn.BatchNorm1d(out_shape*5),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(out_shape*5,out_shape*5),\n",
    "        nn.BatchNorm1d(out_shape*5),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3)\n",
    "    )\n",
    "\n",
    "\n",
    "    self.fc3 = nn.Sequential(\n",
    "        nn.Linear(out_shape*5,out_shape),\n",
    "        nn.BatchNorm1d(out_shape),\n",
    "    )\n",
    "\n",
    "  def forward(self,x,y):\n",
    "    out = self.CLIP(**x)\n",
    "    out = out.logits_per_image\n",
    "    out = self.fc1(out)\n",
    "    out = self.fc2(out)\n",
    "    out = self.fc3(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f34c1711-506c-40af-9f7d-636eae4ddb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,eval_loader,epochs,criterion,optimizer):\n",
    "  \"\"\"\n",
    "  This function trains our model.\n",
    "\n",
    "  model: Our model we need to train\n",
    "\n",
    "  train_loader: contains training data\n",
    "\n",
    "  eval_loader: Contains validation data\n",
    "\n",
    "  epochs: No. of epochs\n",
    "\n",
    "  criterions: Loss function\n",
    "\n",
    "  optimizer: Optimizer for learning\n",
    "\n",
    "  \"\"\"\n",
    "  model = model.cuda()\n",
    "  loss_list=[]\n",
    "  accuracy_list=[]\n",
    "  size = len(train_loader)\n",
    "  eval_size = len(eval_loader)\n",
    "  #val_steps = size//2\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    steps = 1\n",
    "    #initilizing our tqdm progress bar for checking progress\n",
    "    train_tq = tq(train_loader)\n",
    "    for inputs,labels in train_tq:\n",
    "      steps+=1\n",
    "      \"\"\"\n",
    "      add text input info to dict,\n",
    "      Here we are adding our 'input_ids' and 'attention_masks'\n",
    "      which we have already calculated by calling processLabels() function in dataset\n",
    "      to our 'pixel_values' i.e inputs which are from train_loader\n",
    "\n",
    "      dataset.textInput = {\n",
    "        'input_ids' : [tensor]\n",
    "        'attention_mask': [tensor]\n",
    "      }\n",
    "\n",
    "      inputs = {\n",
    "        'pixel_values' : [tensor] of shape (3,224,224)\n",
    "      }\n",
    "\n",
    "      we are adding the 'input_ids' and 'attention_masks'  values so the final input should be\n",
    "\n",
    "      inputs = {\n",
    "        'input_ids' : [tensor]\n",
    "        'attention_mask': [tensor]\n",
    "        'pixel_values' : [tensor] of shape (3,224,224)\n",
    "      }\n",
    "\n",
    "      This is the input to our CLIP model\n",
    "\n",
    "      \"\"\"\n",
    "      for k in dataset.textInput.keys():\n",
    "        inputs[k] = dataset.textInput[k]\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(inputs)\n",
    "      #predictions\n",
    "      preds =  torch.argmax(outputs, dim=1)\n",
    "      #loss\n",
    "      loss = criterion(outputs, labels.cuda())\n",
    "      #accuracy\n",
    "      acc = torch.sum(preds.cpu() == labels.cpu().data).item()\n",
    "      acc = acc/len(preds)\n",
    "      accuracy_list.append(acc)\n",
    "      loss_list.append(loss.item())\n",
    "      #backprop\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      #setting the values of our progress bar\n",
    "      train_tq.set_description(f'TRAIN :: steps: {steps}/{size+1} accuray : {acc*100:.3f} loss: {loss.item():.4f} preds:{preds[0].item()} label:{labels[0].item()}')\n",
    "    #calling evaluate method to check validation accuracy\n",
    "    accuracy,val_loss_list = evaluate(model,eval_loader,criterion)\n",
    "\n",
    "\n",
    "  return {\n",
    "      \"accuracy\":accuracy,\n",
    "      \"train_loss\":loss_list,\n",
    "      \"train_accuracy\":accuracy_list,\n",
    "      \"val_loss\":val_loss_list,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b033f434-34d3-4f13-8bcd-d421eb8f8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,eval_loader,criterion):\n",
    "  #calculates validation accuracy\n",
    "  eval_size = len(eval_loader)\n",
    "  val_acc_list = []\n",
    "  val_loss_list = []\n",
    "  eval_tq = tq(eval_loader)\n",
    "  esteps = 0\n",
    "  model.eval()\n",
    "  for inputs,labels in eval_tq:\n",
    "    esteps+=1\n",
    "    #add text info to dict\n",
    "    for k in dataset.textInput.keys():\n",
    "      inputs[k] = dataset.textInput[k]\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    preds =  torch.argmax(outputs, dim=1)\n",
    "    val_loss = criterion(outputs, labels.cuda())\n",
    "    val_acc = torch.sum(preds.cpu() == labels.cpu().squeeze().data).item()\n",
    "    val_acc = val_acc/len(preds)\n",
    "    val_loss_list.append(val_loss.item())\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    eval_tq.set_description(f'EVAL :=: steps: {esteps}/{eval_size} accuray : {val_acc*100:.3f} loss: {val_loss.item():.4f}')\n",
    "\n",
    "  accuracy = sum(val_acc_list)/len(val_acc_list)\n",
    "  return (accuracy,val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b863a1e7-c682-41e3-b830-54703ee01e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fineCLIP = FineTuneCLIP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e962c3f-d3f8-4d97-9ad3-99e4529d0614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc1.0.weight\n",
      "\t fc1.0.bias\n",
      "\t fc1.1.weight\n",
      "\t fc1.1.bias\n",
      "\t fc2.0.weight\n",
      "\t fc2.0.bias\n",
      "\t fc2.1.weight\n",
      "\t fc2.1.bias\n",
      "\t fc2.3.weight\n",
      "\t fc2.3.bias\n",
      "\t fc2.4.weight\n",
      "\t fc2.4.bias\n",
      "\t fc3.0.weight\n",
      "\t fc3.0.bias\n",
      "\t fc3.1.weight\n",
      "\t fc3.1.bias\n"
     ]
    }
   ],
   "source": [
    "feature_extract = True\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in fineCLIP.named_parameters():\n",
    "        if param.requires_grad == True:#\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in fineCLIP.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0155e03-82cc-4d72-973c-01f9bea04283",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params_to_update,lr=0.0002)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "753e6b71-342f-41bb-8b76-f43be64d2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"model\":fineCLIP,\n",
    "          \"train_loader\":trainLoader,\n",
    "          \"eval_loader\":evalLoader,\n",
    "          \"epochs\":6,\n",
    "          \"criterion\":criterion,\n",
    "          \"optimizer\":optimizer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1805f45e-3fd1-4bd1-b078-d274c0ef67bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d70ba1b17ee4227ad1dd70f89ab3a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30195722ffe54e28b09b992eecd93774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc484a2b45334e44998acf6e35df25d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e89f04a501748a9bdbd7d648942e85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1830a6f607dc4a76a5acf6211772837b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183f877826e242cb9f9c8ed01e444cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5eab03a8ee4e9294ef40411f4dcbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae6a2f9670844c0bb6308824e2a8fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2824f7c1aa3e461b9652ff406049f5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c14b181cf84ef88f424ec3e13d6d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe2653da69543b1988df7022d625875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ccd446f1754c668dce3bcdc5b8ec1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res=train(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70e15263-6ff1-4576-9b9b-1362afd00f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d190b5ccc03a413685bc26d27d38d097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "truth = []\n",
    "fineCLIP.eval()\n",
    "for inputs,label in tq(evalLoader):\n",
    "  #add the attention mask and input_ids to input image pixel values\n",
    "  for k in dataset.textInput.keys():\n",
    "    inputs[k] = dataset.textInput[k]\n",
    "  outputs = fineCLIP(inputs)\n",
    "  probs = outputs.softmax(dim=1)\n",
    "  preds =  torch.argmax(probs, dim=1)\n",
    "  preds=preds.cpu()\n",
    "  for i in preds:\n",
    "    predictions.append(i.item())\n",
    "  for j in label:\n",
    "    truth.append(j.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8096ecc7-099d-4eb3-a0b9-d0c3d7b000d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7312661498708011\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(truth,predictions)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41fd1d11-e483-4dc0-9566-2940337c7603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7179183865230375\n"
     ]
    }
   ],
   "source": [
    "score = f1_score(truth,predictions,average='weighted')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87d08f54-7bec-4fca-9619-96a7a6686d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = scipy.io.loadmat('content/devkit/cars_meta.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e095f742-c3eb-43e7-a275-d4b5fc3b2b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['AM General Hummer SUV 2000'], dtype='<U26'),\n",
       "       array(['Acura RL Sedan 2012'], dtype='<U19'),\n",
       "       array(['Acura TL Sedan 2012'], dtype='<U19'),\n",
       "       array(['Acura TL Type-S 2008'], dtype='<U20'),\n",
       "       array(['Acura TSX Sedan 2012'], dtype='<U20'),\n",
       "       array(['Acura Integra Type R 2001'], dtype='<U25'),\n",
       "       array(['Acura ZDX Hatchback 2012'], dtype='<U24'),\n",
       "       array(['Aston Martin V8 Vantage Convertible 2012'], dtype='<U40'),\n",
       "       array(['Aston Martin V8 Vantage Coupe 2012'], dtype='<U34'),\n",
       "       array(['Aston Martin Virage Convertible 2012'], dtype='<U36'),\n",
       "       array(['Aston Martin Virage Coupe 2012'], dtype='<U30'),\n",
       "       array(['Audi RS 4 Convertible 2008'], dtype='<U26'),\n",
       "       array(['Audi A5 Coupe 2012'], dtype='<U18'),\n",
       "       array(['Audi TTS Coupe 2012'], dtype='<U19'),\n",
       "       array(['Audi R8 Coupe 2012'], dtype='<U18'),\n",
       "       array(['Audi V8 Sedan 1994'], dtype='<U18'),\n",
       "       array(['Audi 100 Sedan 1994'], dtype='<U19'),\n",
       "       array(['Audi 100 Wagon 1994'], dtype='<U19'),\n",
       "       array(['Audi TT Hatchback 2011'], dtype='<U22'),\n",
       "       array(['Audi S6 Sedan 2011'], dtype='<U18'),\n",
       "       array(['Audi S5 Convertible 2012'], dtype='<U24'),\n",
       "       array(['Audi S5 Coupe 2012'], dtype='<U18'),\n",
       "       array(['Audi S4 Sedan 2012'], dtype='<U18'),\n",
       "       array(['Audi S4 Sedan 2007'], dtype='<U18'),\n",
       "       array(['Audi TT RS Coupe 2012'], dtype='<U21'),\n",
       "       array(['BMW ActiveHybrid 5 Sedan 2012'], dtype='<U29'),\n",
       "       array(['BMW 1 Series Convertible 2012'], dtype='<U29'),\n",
       "       array(['BMW 1 Series Coupe 2012'], dtype='<U23'),\n",
       "       array(['BMW 3 Series Sedan 2012'], dtype='<U23'),\n",
       "       array(['BMW 3 Series Wagon 2012'], dtype='<U23'),\n",
       "       array(['BMW 6 Series Convertible 2007'], dtype='<U29'),\n",
       "       array(['BMW X5 SUV 2007'], dtype='<U15'),\n",
       "       array(['BMW X6 SUV 2012'], dtype='<U15'),\n",
       "       array(['BMW M3 Coupe 2012'], dtype='<U17'),\n",
       "       array(['BMW M5 Sedan 2010'], dtype='<U17'),\n",
       "       array(['BMW M6 Convertible 2010'], dtype='<U23'),\n",
       "       array(['BMW X3 SUV 2012'], dtype='<U15'),\n",
       "       array(['BMW Z4 Convertible 2012'], dtype='<U23'),\n",
       "       array(['Bentley Continental Supersports Conv. Convertible 2012'],\n",
       "             dtype='<U54')                                              ,\n",
       "       array(['Bentley Arnage Sedan 2009'], dtype='<U25'),\n",
       "       array(['Bentley Mulsanne Sedan 2011'], dtype='<U27'),\n",
       "       array(['Bentley Continental GT Coupe 2012'], dtype='<U33'),\n",
       "       array(['Bentley Continental GT Coupe 2007'], dtype='<U33'),\n",
       "       array(['Bentley Continental Flying Spur Sedan 2007'], dtype='<U42'),\n",
       "       array(['Bugatti Veyron 16.4 Convertible 2009'], dtype='<U36'),\n",
       "       array(['Bugatti Veyron 16.4 Coupe 2009'], dtype='<U30'),\n",
       "       array(['Buick Regal GS 2012'], dtype='<U19'),\n",
       "       array(['Buick Rainier SUV 2007'], dtype='<U22'),\n",
       "       array(['Buick Verano Sedan 2012'], dtype='<U23'),\n",
       "       array(['Buick Enclave SUV 2012'], dtype='<U22'),\n",
       "       array(['Cadillac CTS-V Sedan 2012'], dtype='<U25'),\n",
       "       array(['Cadillac SRX SUV 2012'], dtype='<U21'),\n",
       "       array(['Cadillac Escalade EXT Crew Cab 2007'], dtype='<U35'),\n",
       "       array(['Chevrolet Silverado 1500 Hybrid Crew Cab 2012'], dtype='<U45'),\n",
       "       array(['Chevrolet Corvette Convertible 2012'], dtype='<U35'),\n",
       "       array(['Chevrolet Corvette ZR1 2012'], dtype='<U27'),\n",
       "       array(['Chevrolet Corvette Ron Fellows Edition Z06 2007'], dtype='<U47'),\n",
       "       array(['Chevrolet Traverse SUV 2012'], dtype='<U27'),\n",
       "       array(['Chevrolet Camaro Convertible 2012'], dtype='<U33'),\n",
       "       array(['Chevrolet HHR SS 2010'], dtype='<U21'),\n",
       "       array(['Chevrolet Impala Sedan 2007'], dtype='<U27'),\n",
       "       array(['Chevrolet Tahoe Hybrid SUV 2012'], dtype='<U31'),\n",
       "       array(['Chevrolet Sonic Sedan 2012'], dtype='<U26'),\n",
       "       array(['Chevrolet Express Cargo Van 2007'], dtype='<U32'),\n",
       "       array(['Chevrolet Avalanche Crew Cab 2012'], dtype='<U33'),\n",
       "       array(['Chevrolet Cobalt SS 2010'], dtype='<U24'),\n",
       "       array(['Chevrolet Malibu Hybrid Sedan 2010'], dtype='<U34'),\n",
       "       array(['Chevrolet TrailBlazer SS 2009'], dtype='<U29'),\n",
       "       array(['Chevrolet Silverado 2500HD Regular Cab 2012'], dtype='<U43'),\n",
       "       array(['Chevrolet Silverado 1500 Classic Extended Cab 2007'], dtype='<U50'),\n",
       "       array(['Chevrolet Express Van 2007'], dtype='<U26'),\n",
       "       array(['Chevrolet Monte Carlo Coupe 2007'], dtype='<U32'),\n",
       "       array(['Chevrolet Malibu Sedan 2007'], dtype='<U27'),\n",
       "       array(['Chevrolet Silverado 1500 Extended Cab 2012'], dtype='<U42'),\n",
       "       array(['Chevrolet Silverado 1500 Regular Cab 2012'], dtype='<U41'),\n",
       "       array(['Chrysler Aspen SUV 2009'], dtype='<U23'),\n",
       "       array(['Chrysler Sebring Convertible 2010'], dtype='<U33'),\n",
       "       array(['Chrysler Town and Country Minivan 2012'], dtype='<U38'),\n",
       "       array(['Chrysler 300 SRT-8 2010'], dtype='<U23'),\n",
       "       array(['Chrysler Crossfire Convertible 2008'], dtype='<U35'),\n",
       "       array(['Chrysler PT Cruiser Convertible 2008'], dtype='<U36'),\n",
       "       array(['Daewoo Nubira Wagon 2002'], dtype='<U24'),\n",
       "       array(['Dodge Caliber Wagon 2012'], dtype='<U24'),\n",
       "       array(['Dodge Caliber Wagon 2007'], dtype='<U24'),\n",
       "       array(['Dodge Caravan Minivan 1997'], dtype='<U26'),\n",
       "       array(['Dodge Ram Pickup 3500 Crew Cab 2010'], dtype='<U35'),\n",
       "       array(['Dodge Ram Pickup 3500 Quad Cab 2009'], dtype='<U35'),\n",
       "       array(['Dodge Sprinter Cargo Van 2009'], dtype='<U29'),\n",
       "       array(['Dodge Journey SUV 2012'], dtype='<U22'),\n",
       "       array(['Dodge Dakota Crew Cab 2010'], dtype='<U26'),\n",
       "       array(['Dodge Dakota Club Cab 2007'], dtype='<U26'),\n",
       "       array(['Dodge Magnum Wagon 2008'], dtype='<U23'),\n",
       "       array(['Dodge Challenger SRT8 2011'], dtype='<U26'),\n",
       "       array(['Dodge Durango SUV 2012'], dtype='<U22'),\n",
       "       array(['Dodge Durango SUV 2007'], dtype='<U22'),\n",
       "       array(['Dodge Charger Sedan 2012'], dtype='<U24'),\n",
       "       array(['Dodge Charger SRT-8 2009'], dtype='<U24'),\n",
       "       array(['Eagle Talon Hatchback 1998'], dtype='<U26'),\n",
       "       array(['FIAT 500 Abarth 2012'], dtype='<U20'),\n",
       "       array(['FIAT 500 Convertible 2012'], dtype='<U25'),\n",
       "       array(['Ferrari FF Coupe 2012'], dtype='<U21'),\n",
       "       array(['Ferrari California Convertible 2012'], dtype='<U35'),\n",
       "       array(['Ferrari 458 Italia Convertible 2012'], dtype='<U35'),\n",
       "       array(['Ferrari 458 Italia Coupe 2012'], dtype='<U29'),\n",
       "       array(['Fisker Karma Sedan 2012'], dtype='<U23'),\n",
       "       array(['Ford F-450 Super Duty Crew Cab 2012'], dtype='<U35'),\n",
       "       array(['Ford Mustang Convertible 2007'], dtype='<U29'),\n",
       "       array(['Ford Freestar Minivan 2007'], dtype='<U26'),\n",
       "       array(['Ford Expedition EL SUV 2009'], dtype='<U27'),\n",
       "       array(['Ford Edge SUV 2012'], dtype='<U18'),\n",
       "       array(['Ford Ranger SuperCab 2011'], dtype='<U25'),\n",
       "       array(['Ford GT Coupe 2006'], dtype='<U18'),\n",
       "       array(['Ford F-150 Regular Cab 2012'], dtype='<U27'),\n",
       "       array(['Ford F-150 Regular Cab 2007'], dtype='<U27'),\n",
       "       array(['Ford Focus Sedan 2007'], dtype='<U21'),\n",
       "       array(['Ford E-Series Wagon Van 2012'], dtype='<U28'),\n",
       "       array(['Ford Fiesta Sedan 2012'], dtype='<U22'),\n",
       "       array(['GMC Terrain SUV 2012'], dtype='<U20'),\n",
       "       array(['GMC Savana Van 2012'], dtype='<U19'),\n",
       "       array(['GMC Yukon Hybrid SUV 2012'], dtype='<U25'),\n",
       "       array(['GMC Acadia SUV 2012'], dtype='<U19'),\n",
       "       array(['GMC Canyon Extended Cab 2012'], dtype='<U28'),\n",
       "       array(['Geo Metro Convertible 1993'], dtype='<U26'),\n",
       "       array(['HUMMER H3T Crew Cab 2010'], dtype='<U24'),\n",
       "       array(['HUMMER H2 SUT Crew Cab 2009'], dtype='<U27'),\n",
       "       array(['Honda Odyssey Minivan 2012'], dtype='<U26'),\n",
       "       array(['Honda Odyssey Minivan 2007'], dtype='<U26'),\n",
       "       array(['Honda Accord Coupe 2012'], dtype='<U23'),\n",
       "       array(['Honda Accord Sedan 2012'], dtype='<U23'),\n",
       "       array(['Hyundai Veloster Hatchback 2012'], dtype='<U31'),\n",
       "       array(['Hyundai Santa Fe SUV 2012'], dtype='<U25'),\n",
       "       array(['Hyundai Tucson SUV 2012'], dtype='<U23'),\n",
       "       array(['Hyundai Veracruz SUV 2012'], dtype='<U25'),\n",
       "       array(['Hyundai Sonata Hybrid Sedan 2012'], dtype='<U32'),\n",
       "       array(['Hyundai Elantra Sedan 2007'], dtype='<U26'),\n",
       "       array(['Hyundai Accent Sedan 2012'], dtype='<U25'),\n",
       "       array(['Hyundai Genesis Sedan 2012'], dtype='<U26'),\n",
       "       array(['Hyundai Sonata Sedan 2012'], dtype='<U25'),\n",
       "       array(['Hyundai Elantra Touring Hatchback 2012'], dtype='<U38'),\n",
       "       array(['Hyundai Azera Sedan 2012'], dtype='<U24'),\n",
       "       array(['Infiniti G Coupe IPL 2012'], dtype='<U25'),\n",
       "       array(['Infiniti QX56 SUV 2011'], dtype='<U22'),\n",
       "       array(['Isuzu Ascender SUV 2008'], dtype='<U23'),\n",
       "       array(['Jaguar XK XKR 2012'], dtype='<U18'),\n",
       "       array(['Jeep Patriot SUV 2012'], dtype='<U21'),\n",
       "       array(['Jeep Wrangler SUV 2012'], dtype='<U22'),\n",
       "       array(['Jeep Liberty SUV 2012'], dtype='<U21'),\n",
       "       array(['Jeep Grand Cherokee SUV 2012'], dtype='<U28'),\n",
       "       array(['Jeep Compass SUV 2012'], dtype='<U21'),\n",
       "       array(['Lamborghini Reventon Coupe 2008'], dtype='<U31'),\n",
       "       array(['Lamborghini Aventador Coupe 2012'], dtype='<U32'),\n",
       "       array(['Lamborghini Gallardo LP 570-4 Superleggera 2012'], dtype='<U47'),\n",
       "       array(['Lamborghini Diablo Coupe 2001'], dtype='<U29'),\n",
       "       array(['Land Rover Range Rover SUV 2012'], dtype='<U31'),\n",
       "       array(['Land Rover LR2 SUV 2012'], dtype='<U23'),\n",
       "       array(['Lincoln Town Car Sedan 2011'], dtype='<U27'),\n",
       "       array(['MINI Cooper Roadster Convertible 2012'], dtype='<U37'),\n",
       "       array(['Maybach Landaulet Convertible 2012'], dtype='<U34'),\n",
       "       array(['Mazda Tribute SUV 2011'], dtype='<U22'),\n",
       "       array(['McLaren MP4-12C Coupe 2012'], dtype='<U26'),\n",
       "       array(['Mercedes-Benz 300-Class Convertible 1993'], dtype='<U40'),\n",
       "       array(['Mercedes-Benz C-Class Sedan 2012'], dtype='<U32'),\n",
       "       array(['Mercedes-Benz SL-Class Coupe 2009'], dtype='<U33'),\n",
       "       array(['Mercedes-Benz E-Class Sedan 2012'], dtype='<U32'),\n",
       "       array(['Mercedes-Benz S-Class Sedan 2012'], dtype='<U32'),\n",
       "       array(['Mercedes-Benz Sprinter Van 2012'], dtype='<U31'),\n",
       "       array(['Mitsubishi Lancer Sedan 2012'], dtype='<U28'),\n",
       "       array(['Nissan Leaf Hatchback 2012'], dtype='<U26'),\n",
       "       array(['Nissan NV Passenger Van 2012'], dtype='<U28'),\n",
       "       array(['Nissan Juke Hatchback 2012'], dtype='<U26'),\n",
       "       array(['Nissan 240SX Coupe 1998'], dtype='<U23'),\n",
       "       array(['Plymouth Neon Coupe 1999'], dtype='<U24'),\n",
       "       array(['Porsche Panamera Sedan 2012'], dtype='<U27'),\n",
       "       array(['Ram C/V Cargo Van Minivan 2012'], dtype='<U30'),\n",
       "       array(['Rolls-Royce Phantom Drophead Coupe Convertible 2012'],\n",
       "             dtype='<U51')                                           ,\n",
       "       array(['Rolls-Royce Ghost Sedan 2012'], dtype='<U28'),\n",
       "       array(['Rolls-Royce Phantom Sedan 2012'], dtype='<U30'),\n",
       "       array(['Scion xD Hatchback 2012'], dtype='<U23'),\n",
       "       array(['Spyker C8 Convertible 2009'], dtype='<U26'),\n",
       "       array(['Spyker C8 Coupe 2009'], dtype='<U20'),\n",
       "       array(['Suzuki Aerio Sedan 2007'], dtype='<U23'),\n",
       "       array(['Suzuki Kizashi Sedan 2012'], dtype='<U25'),\n",
       "       array(['Suzuki SX4 Hatchback 2012'], dtype='<U25'),\n",
       "       array(['Suzuki SX4 Sedan 2012'], dtype='<U21'),\n",
       "       array(['Tesla Model S Sedan 2012'], dtype='<U24'),\n",
       "       array(['Toyota Sequoia SUV 2012'], dtype='<U23'),\n",
       "       array(['Toyota Camry Sedan 2012'], dtype='<U23'),\n",
       "       array(['Toyota Corolla Sedan 2012'], dtype='<U25'),\n",
       "       array(['Toyota 4Runner SUV 2012'], dtype='<U23'),\n",
       "       array(['Volkswagen Golf Hatchback 2012'], dtype='<U30'),\n",
       "       array(['Volkswagen Golf Hatchback 1991'], dtype='<U30'),\n",
       "       array(['Volkswagen Beetle Hatchback 2012'], dtype='<U32'),\n",
       "       array(['Volvo C30 Hatchback 2012'], dtype='<U24'),\n",
       "       array(['Volvo 240 Sedan 1993'], dtype='<U20'),\n",
       "       array(['Volvo XC90 SUV 2007'], dtype='<U19'),\n",
       "       array(['smart fortwo Convertible 2012'], dtype='<U29')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_data['class_names'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3764bc8d-755a-4898-9e5a-0cdf9ecbe12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a93190-f5e2-4e15-b153-9048a787e1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
